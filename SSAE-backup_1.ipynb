{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input dropout + Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from codes.utils import *\n",
    "from codes.process import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "random_seed=42\n",
    "bed_root = '/home2/jpark/Projects/prs/data/bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_train_type = 'test'\n",
    "fold_num = 1\n",
    "in_fold_num = 1\n",
    "y_value = 'y'\n",
    "ex_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_y_ex = pd.read_csv(f\"{get_bed_path('keep_bed_yi_ex', extract_train_type, fold_num, in_fold_num=in_fold_num, y=y_value, ex=ex_num)}.raw\",\n",
    "    delim_whitespace=True)\n",
    "bed_y_ex = bed_y_ex.iloc[:, [1] + list(range(6, len(bed_y_ex.columns)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IID</th>\n",
       "      <th>1:28875134:A:G_G</th>\n",
       "      <th>1:87968670:A:C_C</th>\n",
       "      <th>1:161477945:C:T_T</th>\n",
       "      <th>2:227817651:A:C_C</th>\n",
       "      <th>3:2436730:C:A_A</th>\n",
       "      <th>3:2439813:A:C_C</th>\n",
       "      <th>3:2526760:G:A_A</th>\n",
       "      <th>3:2543220:C:T_T</th>\n",
       "      <th>3:2549167:G:A_A</th>\n",
       "      <th>...</th>\n",
       "      <th>20:51352171:T:G_T</th>\n",
       "      <th>20:51353834:G:A_G</th>\n",
       "      <th>20:51355272:A:G_G</th>\n",
       "      <th>20:51356520:A:G_G</th>\n",
       "      <th>20:51361284:C:A_C</th>\n",
       "      <th>20:51363417:G:C_G</th>\n",
       "      <th>20:51367978:G:T_G</th>\n",
       "      <th>20:51371580:G:A_A</th>\n",
       "      <th>20:51371657:A:G_G</th>\n",
       "      <th>20:51372200:G:T_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNIHGR000009_KNIHGR000009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNIHGR000019_KNIHGR000019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNIHGR000051_KNIHGR000051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNIHGR000070_KNIHGR000070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNIHGR000121_KNIHGR000121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>KNIHGR009575_KNIHGR009575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>KNIHGR009587_KNIHGR009587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>KNIHGR009589_KNIHGR009589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>KNIHGR009597_KNIHGR009597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>KNIHGR009601_KNIHGR009601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           IID  1:28875134:A:G_G  1:87968670:A:C_C  \\\n",
       "0    KNIHGR000009_KNIHGR000009                 0                 0   \n",
       "1    KNIHGR000019_KNIHGR000019                 0                 0   \n",
       "2    KNIHGR000051_KNIHGR000051                 0                 0   \n",
       "3    KNIHGR000070_KNIHGR000070                 0                 0   \n",
       "4    KNIHGR000121_KNIHGR000121                 0                 0   \n",
       "..                         ...               ...               ...   \n",
       "780  KNIHGR009575_KNIHGR009575                 0                 0   \n",
       "781  KNIHGR009587_KNIHGR009587                 0                 0   \n",
       "782  KNIHGR009589_KNIHGR009589                 0                 0   \n",
       "783  KNIHGR009597_KNIHGR009597                 0                 0   \n",
       "784  KNIHGR009601_KNIHGR009601                 0                 0   \n",
       "\n",
       "     1:161477945:C:T_T  2:227817651:A:C_C  3:2436730:C:A_A  3:2439813:A:C_C  \\\n",
       "0                    0                  0                0                0   \n",
       "1                    0                  0                0                0   \n",
       "2                    0                  0                0                0   \n",
       "3                    0                  0                0                0   \n",
       "4                    0                  0                0                0   \n",
       "..                 ...                ...              ...              ...   \n",
       "780                  0                  0                0                0   \n",
       "781                  0                  0                0                0   \n",
       "782                  0                  0                0                0   \n",
       "783                  0                  0                0                0   \n",
       "784                  0                  0                0                0   \n",
       "\n",
       "     3:2526760:G:A_A  3:2543220:C:T_T  3:2549167:G:A_A  ...  \\\n",
       "0                  0                0                0  ...   \n",
       "1                  0                0                0  ...   \n",
       "2                  0                0                0  ...   \n",
       "3                  0                0                0  ...   \n",
       "4                  0                0                0  ...   \n",
       "..               ...              ...              ...  ...   \n",
       "780                0                0                0  ...   \n",
       "781                0                0                0  ...   \n",
       "782                0                0                0  ...   \n",
       "783                0                0                0  ...   \n",
       "784                0                0                0  ...   \n",
       "\n",
       "     20:51352171:T:G_T  20:51353834:G:A_G  20:51355272:A:G_G  \\\n",
       "0                    0                  0                  0   \n",
       "1                    0                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    0                  0                  0   \n",
       "4                    0                  0                  0   \n",
       "..                 ...                ...                ...   \n",
       "780                  0                  0                  0   \n",
       "781                  2                  2                  0   \n",
       "782                  1                  1                  0   \n",
       "783                  0                  0                  0   \n",
       "784                  0                  0                  0   \n",
       "\n",
       "     20:51356520:A:G_G  20:51361284:C:A_C  20:51363417:G:C_G  \\\n",
       "0                    0                  0                  0   \n",
       "1                    0                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    0                  0                  0   \n",
       "4                    0                  0                  0   \n",
       "..                 ...                ...                ...   \n",
       "780                  0                  0                  0   \n",
       "781                  0                  2                  2   \n",
       "782                  0                  1                  1   \n",
       "783                  0                  0                  0   \n",
       "784                  0                  0                  0   \n",
       "\n",
       "     20:51367978:G:T_G  20:51371580:G:A_A  20:51371657:A:G_G  \\\n",
       "0                    0                  0                  0   \n",
       "1                    0                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    0                  0                  0   \n",
       "4                    0                  0                  0   \n",
       "..                 ...                ...                ...   \n",
       "780                  0                  0                  0   \n",
       "781                  2                  0                  0   \n",
       "782                  1                  0                  0   \n",
       "783                  0                  0                  0   \n",
       "784                  0                  0                  0   \n",
       "\n",
       "     20:51372200:G:T_T  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "..                 ...  \n",
       "780                  0  \n",
       "781                  0  \n",
       "782                  0  \n",
       "783                  0  \n",
       "784                  0  \n",
       "\n",
       "[785 rows x 101 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bed_y_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "\n",
    "\n",
    "# 맷플롯립 설정\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "plt.rcParams['font.family'] = 'NanumBarunGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 그림을 저장할 폴더\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"autoencoders\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image, shape=[28, 28]):\n",
    "    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_multiple_images(images, n_rows, n_cols, pad=2):\n",
    "    images = images - images.min()  # 최소값을 0으로 만들어 패딩이 하얗게 보이도록 합니다.\n",
    "    w,h = images.shape[1:]\n",
    "    image = np.zeros(((w+pad)*n_rows+pad, (h+pad)*n_cols+pad))\n",
    "    for y in range(n_rows):\n",
    "        for x in range(n_cols):\n",
    "            image[(y*(h+pad)+pad):(y*(h+pad)+pad+h),(x*(w+pad)+pad):(x*(w+pad)+pad+w)] = images[y*n_cols+x]\n",
    "    plt.imshow(image, cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0.95]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = 0.1\n",
    "q = np.linspace(0.001, 0.999, 500)\n",
    "kl_div = p * np.log(p / q) + (1 - p) * np.log((1 - p) / (1 - q))\n",
    "mse = (p - q)**2\n",
    "plt.plot([p, p], [0, 0.3], \"k:\")\n",
    "plt.text(0.05, 0.32, \"target spart\", fontsize=14)\n",
    "plt.plot(q, kl_div, \"b-\", label=\"KLD\")\n",
    "plt.plot(q, mse, \"r--\", label=\"MSE\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"real sparse\")\n",
    "plt.ylabel(\"cost\", rotation=0)\n",
    "plt.axis([0, 1, 0, 0.95])\n",
    "#save_fig(\"sparsity_loss_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150  # 코딩 유닛\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reconstructed_digits(X, outputs, model_path = None, n_test_digits = 2):\n",
    "    with tf.Session() as sess:\n",
    "        if model_path:\n",
    "            saver.restore(sess, model_path)\n",
    "#         X_test = mnist.test.images[:n_test_digits]\n",
    "        outputs_val = outputs.eval(feed_dict={X: X_test[:n_test_digits]})\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 3 * n_test_digits))\n",
    "    for digit_index in range(n_test_digits):\n",
    "        plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n",
    "        plot_image(X_test[digit_index])\n",
    "        plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n",
    "        plot_image(outputs_val[digit_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-39-fbcd27c8fd3e>:13: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f43481694a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f43481694a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f43481694a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7f43481694a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349d5a128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349d5a128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349d5a128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349d5a128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f43481694a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f43481694a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f43481694a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f43481694a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "def kl_divergence(p, q):\n",
    "    # 쿨백 라이블러 발산\n",
    "    return p * tf.log(p / q) + (1 - p) * tf.log((1 - p) / (1 - q))\n",
    "\n",
    "learning_rate = 0.01\n",
    "sparsity_target = 0.1\n",
    "sparsity_weight = 0.2\n",
    "dropout_rate = 0.3\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.sigmoid) # 책에는 없음\n",
    "outputs = tf.layers.dense(hidden1, n_outputs)                     # 책에는 없음\n",
    "\n",
    "hidden1_mean = tf.reduce_mean(hidden1, axis=0) # 배치 평균\n",
    "sparsity_loss = tf.reduce_sum(kl_divergence(sparsity_target, hidden1_mean))\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X)) # MSE\n",
    "loss = reconstruction_loss + sparsity_weight * sparsity_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 훈련 MSE: 0.06527311 \t희소 손실: 0.09935042 \t전체 손실: 0.0851432\n",
      "1 훈련 MSE: 0.051947646 \t희소 손실: 0.09063869 \t전체 손실: 0.070075385\n",
      "2 훈련 MSE: 0.04862513 \t희소 손실: 0.0065766466 \t전체 손실: 0.04994046\n",
      "3 훈련 MSE: 0.044821847 \t희소 손실: 0.0744123 \t전체 손실: 0.059704307\n",
      "4 훈련 MSE: 0.037456583 \t희소 손실: 0.010950893 \t전체 손실: 0.039646763\n",
      "5 훈련 MSE: 0.032592904 \t희소 손실: 0.0224674 \t전체 손실: 0.037086383\n",
      "6 훈련 MSE: 0.029170336 \t희소 손실: 0.09132383 \t전체 손실: 0.047435105\n",
      "7 훈련 MSE: 0.0268845 \t희소 손실: 0.013720078 \t전체 손실: 0.029628515\n",
      "8 훈련 MSE: 0.025254773 \t희소 손실: 0.03548964 \t전체 손실: 0.0323527\n",
      "9 훈련 MSE: 0.02391695 \t희소 손실: 0.026032042 \t전체 손실: 0.029123358\n",
      "10 훈련 MSE: 0.021673322 \t희소 손실: 0.030984594 \t전체 손실: 0.027870242\n",
      "11 훈련 MSE: 0.020857202 \t희소 손실: 0.01684498 \t전체 손실: 0.024226198\n",
      "12 훈련 MSE: 0.018903565 \t희소 손실: 0.023043407 \t전체 손실: 0.023512246\n",
      "13 훈련 MSE: 0.018145408 \t희소 손실: 0.02079668 \t전체 손실: 0.022304745\n",
      "14 훈련 MSE: 0.017918209 \t희소 손실: 0.021242063 \t전체 손실: 0.022166621\n",
      "15 훈련 MSE: 0.0165026 \t희소 손실: 0.03806768 \t전체 손실: 0.024116136\n",
      "16 훈련 MSE: 0.016992481 \t희소 손실: 0.02122283 \t전체 손실: 0.021237047\n",
      "17 훈련 MSE: 0.016079359 \t희소 손실: 0.08925571 \t전체 손실: 0.033930503\n",
      "18 훈련 MSE: 0.016277768 \t희소 손실: 0.032952726 \t전체 손실: 0.022868313\n",
      "19 훈련 MSE: 0.015441901 \t희소 손실: 0.025886402 \t전체 손실: 0.020619182\n",
      "20 훈련 MSE: 0.014931146 \t희소 손실: 0.052645378 \t전체 손실: 0.02546022\n",
      "21 훈련 MSE: 0.014459784 \t희소 손실: 0.014053569 \t전체 손실: 0.017270498\n",
      "22 훈련 MSE: 0.014523728 \t희소 손실: 0.036586914 \t전체 손실: 0.02184111\n",
      "23 훈련 MSE: 0.014091724 \t희소 손실: 0.02131862 \t전체 손실: 0.018355448\n",
      "24 훈련 MSE: 0.01449971 \t희소 손실: 0.04462254 \t전체 손실: 0.02342422\n",
      "25 훈련 MSE: 0.013871658 \t희소 손실: 0.07357511 \t전체 손실: 0.02858668\n",
      "26 훈련 MSE: 0.013463253 \t희소 손실: 0.037069187 \t전체 손실: 0.020877091\n",
      "27 훈련 MSE: 0.013443749 \t희소 손실: 0.027547212 \t전체 손실: 0.018953193\n",
      "28 훈련 MSE: 0.013493781 \t희소 손실: 0.025581721 \t전체 손실: 0.018610125\n",
      "29 훈련 MSE: 0.013039957 \t희소 손실: 0.02734102 \t전체 손실: 0.01850816\n",
      "30 훈련 MSE: 0.013450763 \t희소 손실: 0.03761311 \t전체 손실: 0.020973384\n",
      "31 훈련 MSE: 0.01221781 \t희소 손실: 0.027567204 \t전체 손실: 0.017731251\n",
      "32 훈련 MSE: 0.011911542 \t희소 손실: 0.076549694 \t전체 손실: 0.027221482\n",
      "33 훈련 MSE: 0.012310927 \t희소 손실: 0.019983215 \t전체 손실: 0.01630757\n",
      "34 훈련 MSE: 0.012861528 \t희소 손실: 0.07707231 \t전체 손실: 0.028275989\n",
      "35 훈련 MSE: 0.012305659 \t희소 손실: 0.03995628 \t전체 손실: 0.020296916\n",
      "36 훈련 MSE: 0.0119752325 \t희소 손실: 0.03230177 \t전체 손실: 0.018435586\n",
      "37 훈련 MSE: 0.011817559 \t희소 손실: 0.020137513 \t전체 손실: 0.01584506\n",
      "38 훈련 MSE: 0.0121472115 \t희소 손실: 0.08219446 \t전체 손실: 0.028586105\n",
      "39 훈련 MSE: 0.012013522 \t희소 손실: 0.027696973 \t전체 손실: 0.017552916\n",
      "40 훈련 MSE: 0.011557098 \t희소 손실: 0.025511742 \t전체 손실: 0.016659446\n",
      "41 훈련 MSE: 0.011605161 \t희소 손실: 0.03926512 \t전체 손실: 0.019458186\n",
      "42 훈련 MSE: 0.011197752 \t희소 손실: 0.055850845 \t전체 손실: 0.02236792\n",
      "43 훈련 MSE: 0.0112258205 \t희소 손실: 0.038461726 \t전체 손실: 0.018918166\n",
      "44 훈련 MSE: 0.0110047655 \t희소 손실: 0.031991422 \t전체 손실: 0.01740305\n",
      "45 훈련 MSE: 0.011409296 \t희소 손실: 0.032490287 \t전체 손실: 0.017907353\n",
      "46 훈련 MSE: 0.011205019 \t희소 손실: 0.027168076 \t전체 손실: 0.016638635\n",
      "47 훈련 MSE: 0.010935291 \t희소 손실: 0.031909723 \t전체 손실: 0.017317235\n",
      "48 훈련 MSE: 0.011520689 \t희소 손실: 0.069486424 \t전체 손실: 0.025417974\n",
      "49 훈련 MSE: 0.0113682635 \t희소 손실: 0.062589936 \t전체 손실: 0.023886252\n",
      "50 훈련 MSE: 0.011206595 \t희소 손실: 0.031141806 \t전체 손실: 0.017434957\n",
      "51 훈련 MSE: 0.01155969 \t희소 손실: 0.034651957 \t전체 손실: 0.018490082\n",
      "52 훈련 MSE: 0.010990642 \t희소 손실: 0.03581827 \t전체 손실: 0.018154297\n",
      "53 훈련 MSE: 0.011488362 \t희소 손실: 0.06766316 \t전체 손실: 0.025020994\n",
      "54 훈련 MSE: 0.011800454 \t희소 손실: 0.10061771 \t전체 손실: 0.031923994\n",
      "55 훈련 MSE: 0.010521001 \t희소 손실: 0.04038803 \t전체 손실: 0.018598607\n",
      "56 훈련 MSE: 0.010664757 \t희소 손실: 0.03469235 \t전체 손실: 0.017603228\n",
      "57 훈련 MSE: 0.011270091 \t희소 손실: 0.03867765 \t전체 손실: 0.01900562\n",
      "58 훈련 MSE: 0.010799536 \t희소 손실: 0.0489386 \t전체 손실: 0.020587254\n",
      "59 훈련 MSE: 0.011269692 \t희소 손실: 0.048716873 \t전체 손실: 0.021013066\n",
      "60 훈련 MSE: 0.010222624 \t희소 손실: 0.058900908 \t전체 손실: 0.022002805\n",
      "61 훈련 MSE: 0.010337545 \t희소 손실: 0.035636745 \t전체 손실: 0.017464895\n",
      "62 훈련 MSE: 0.010955446 \t희소 손실: 0.10356376 \t전체 손실: 0.0316682\n",
      "63 훈련 MSE: 0.011227366 \t희소 손실: 0.06620208 \t전체 손실: 0.024467781\n",
      "64 훈련 MSE: 0.010660345 \t희소 손실: 0.054265052 \t전체 손실: 0.021513354\n",
      "65 훈련 MSE: 0.010310024 \t희소 손실: 0.050509926 \t전체 손실: 0.02041201\n",
      "66 훈련 MSE: 0.010144065 \t희소 손실: 0.039047424 \t전체 손실: 0.01795355\n",
      "67 훈련 MSE: 0.01027371 \t희소 손실: 0.05228518 \t전체 손실: 0.020730745\n",
      "68 훈련 MSE: 0.01048308 \t희소 손실: 0.039513193 \t전체 손실: 0.01838572\n",
      "69 훈련 MSE: 0.010741453 \t희소 손실: 0.050029337 \t전체 손실: 0.02074732\n",
      "70 훈련 MSE: 0.010598309 \t희소 손실: 0.03500409 \t전체 손실: 0.017599128\n",
      "71 훈련 MSE: 0.0102593275 \t희소 손실: 0.06856731 \t전체 손실: 0.02397279\n",
      "72 훈련 MSE: 0.01090529 \t희소 손실: 0.07318746 \t전체 손실: 0.025542783\n",
      "73 훈련 MSE: 0.010866517 \t희소 손실: 0.09371258 \t전체 손실: 0.029609034\n",
      "74 훈련 MSE: 0.010761066 \t희소 손실: 0.044072557 \t전체 손실: 0.019575577\n",
      "75 훈련 MSE: 0.009980894 \t희소 손실: 0.03806929 \t전체 손실: 0.017594751\n",
      "76 훈련 MSE: 0.009779492 \t희소 손실: 0.106681265 \t전체 손실: 0.031115746\n",
      "77 훈련 MSE: 0.010566727 \t희소 손실: 0.04594127 \t전체 손실: 0.019754982\n",
      "78 훈련 MSE: 0.010031349 \t희소 손실: 0.105050966 \t전체 손실: 0.031041544\n",
      "79 훈련 MSE: 0.010359246 \t희소 손실: 0.07262573 \t전체 손실: 0.024884392\n",
      "80 훈련 MSE: 0.010200029 \t희소 손실: 0.10637725 \t전체 손실: 0.03147548\n",
      "81 훈련 MSE: 0.009767719 \t희소 손실: 0.076014735 \t전체 손실: 0.024970666\n",
      "82 훈련 MSE: 0.00980765 \t희소 손실: 0.052915797 \t전체 손실: 0.020390809\n",
      "83 훈련 MSE: 0.009986576 \t희소 손실: 0.052038047 \t전체 손실: 0.020394186\n",
      "84 훈련 MSE: 0.010116541 \t희소 손실: 0.14149454 \t전체 손실: 0.03841545\n",
      "85 훈련 MSE: 0.010390304 \t희소 손실: 0.10534893 \t전체 손실: 0.03146009\n",
      "86 훈련 MSE: 0.010475547 \t희소 손실: 0.03729372 \t전체 손실: 0.01793429\n",
      "87 훈련 MSE: 0.010366799 \t희소 손실: 0.05924314 \t전체 손실: 0.022215426\n",
      "88 훈련 MSE: 0.0105269505 \t희소 손실: 0.08844293 \t전체 손실: 0.028215535\n",
      "89 훈련 MSE: 0.0102775935 \t희소 손실: 0.06978642 \t전체 손실: 0.024234878\n",
      "90 훈련 MSE: 0.010503798 \t희소 손실: 0.03831139 \t전체 손실: 0.018166076\n",
      "91 훈련 MSE: 0.010009973 \t희소 손실: 0.12002553 \t전체 손실: 0.034015078\n",
      "92 훈련 MSE: 0.011262044 \t희소 손실: 0.050995376 \t전체 손실: 0.02146112\n",
      "93 훈련 MSE: 0.01039011 \t희소 손실: 0.06217424 \t전체 손실: 0.022824958\n",
      "94 훈련 MSE: 0.0101997815 \t희소 손실: 0.0932789 \t전체 손실: 0.028855562\n",
      "95 훈련 MSE: 0.010523544 \t희소 손실: 0.05896977 \t전체 손실: 0.022317499\n",
      "96 훈련 MSE: 0.009823534 \t희소 손실: 0.05447548 \t전체 손실: 0.02071863\n",
      "97 훈련 MSE: 0.010520209 \t희소 손실: 0.059858974 \t전체 손실: 0.022492003\n",
      "98 훈련 MSE: 0.010621844 \t희소 손실: 0.09750325 \t전체 손실: 0.030122494\n",
      "99 훈련 MSE: 0.009707531 \t희소 손실: 0.043113437 \t전체 손실: 0.018330218\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = len(X_train) // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = next(shuffle_batch(X_train, y_train, batch_size))\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        reconstruction_loss_val, sparsity_loss_val, loss_val = sess.run([reconstruction_loss, sparsity_loss, loss], feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"훈련 MSE:\", reconstruction_loss_val, \"\\t희소 손실:\", sparsity_loss_val, \"\\t전체 손실:\", loss_val)\n",
    "        saver.save(sess, \"./my_model_sparse.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /bin2/pkg_python36/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./my_model_sparse.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_reconstructed_digits(X, outputs, \"./my_model_sparse.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349da2e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349da2e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349da2e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349da2e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349d04cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349d04cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349d04cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4349d04cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /bin2/pkg_python36/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.sigmoid)\n",
    "logits = tf.layers.dense(hidden1, n_outputs)\n",
    "outputs = tf.nn.sigmoid(logits)\n",
    "\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\n",
    "reconstruction_loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 훈련 MSE: 0.7047666 \t희소 손실: 0.12352318 \t전체 손실: 0.09142406\n",
      "1 훈련 MSE: 0.704796 \t희소 손실: 0.019605529 \t전체 손실: 0.05858742\n",
      "2 훈련 MSE: 0.7048345 \t희소 손실: 0.028799854 \t전체 손실: 0.054506186\n",
      "3 훈련 MSE: 0.70477927 \t희소 손실: 0.008937162 \t전체 손실: 0.045784224\n",
      "4 훈련 MSE: 0.70475614 \t희소 손실: 0.07770297 \t전체 손실: 0.05621028\n",
      "5 훈련 MSE: 0.7046035 \t희소 손실: 0.014777578 \t전체 손실: 0.037430603\n",
      "6 훈련 MSE: 0.7048179 \t희소 손실: 0.010760792 \t전체 손실: 0.032250192\n",
      "7 훈련 MSE: 0.70467716 \t희소 손실: 0.006685371 \t전체 손실: 0.028559342\n",
      "8 훈련 MSE: 0.70488346 \t희소 손실: 0.014640239 \t전체 손실: 0.027989157\n",
      "9 훈련 MSE: 0.7049954 \t희소 손실: 0.010540727 \t전체 손실: 0.025672361\n",
      "10 훈련 MSE: 0.70476043 \t희소 손실: 0.017074438 \t전체 손실: 0.025290703\n",
      "11 훈련 MSE: 0.7047554 \t희소 손실: 0.03934033 \t전체 손실: 0.029316306\n",
      "12 훈련 MSE: 0.70469606 \t희소 손실: 0.019014362 \t전체 손실: 0.024640704\n",
      "13 훈련 MSE: 0.70488685 \t희소 손실: 0.030627202 \t전체 손실: 0.025302013\n",
      "14 훈련 MSE: 0.70481926 \t희소 손실: 0.014720345 \t전체 손실: 0.020566199\n",
      "15 훈련 MSE: 0.7045547 \t희소 손실: 0.03210661 \t전체 손실: 0.023378175\n",
      "16 훈련 MSE: 0.7047551 \t희소 손실: 0.016374063 \t전체 손실: 0.020019844\n",
      "17 훈련 MSE: 0.7048573 \t희소 손실: 0.014826399 \t전체 손실: 0.019578878\n",
      "18 훈련 MSE: 0.70477533 \t희소 손실: 0.023401786 \t전체 손실: 0.020934856\n",
      "19 훈련 MSE: 0.70472986 \t희소 손실: 0.021583013 \t전체 손실: 0.019544411\n",
      "20 훈련 MSE: 0.7048758 \t희소 손실: 0.063320175 \t전체 손실: 0.027692698\n",
      "21 훈련 MSE: 0.70483166 \t희소 손실: 0.051129993 \t전체 손실: 0.02441512\n",
      "22 훈련 MSE: 0.7048301 \t희소 손실: 0.057694986 \t전체 손실: 0.026278095\n",
      "23 훈련 MSE: 0.70484006 \t희소 손실: 0.019251088 \t전체 손실: 0.018211883\n",
      "24 훈련 MSE: 0.7046763 \t희소 손실: 0.017222723 \t전체 손실: 0.017566694\n",
      "25 훈련 MSE: 0.7047307 \t희소 손실: 0.019990468 \t전체 손실: 0.01739691\n",
      "26 훈련 MSE: 0.7049238 \t희소 손실: 0.04430051 \t전체 손실: 0.023023173\n",
      "27 훈련 MSE: 0.7047136 \t희소 손실: 0.046981275 \t전체 손실: 0.023599796\n",
      "28 훈련 MSE: 0.7045709 \t희소 손실: 0.039977424 \t전체 손실: 0.02142844\n",
      "29 훈련 MSE: 0.7049996 \t희소 손실: 0.06922811 \t전체 손실: 0.028003555\n",
      "30 훈련 MSE: 0.70485514 \t희소 손실: 0.022128401 \t전체 손실: 0.017567098\n",
      "31 훈련 MSE: 0.70476186 \t희소 손실: 0.062447727 \t전체 손실: 0.025119763\n",
      "32 훈련 MSE: 0.7045395 \t희소 손실: 0.038811553 \t전체 손실: 0.0205707\n",
      "33 훈련 MSE: 0.7047245 \t희소 손실: 0.04363279 \t전체 손실: 0.021302916\n",
      "34 훈련 MSE: 0.70466316 \t희소 손실: 0.043620918 \t전체 손실: 0.020632096\n",
      "35 훈련 MSE: 0.7046484 \t희소 손실: 0.026722973 \t전체 손실: 0.017461685\n",
      "36 훈련 MSE: 0.7045358 \t희소 손실: 0.027665464 \t전체 손실: 0.017213417\n",
      "37 훈련 MSE: 0.70476717 \t희소 손실: 0.029253626 \t전체 손실: 0.01754222\n",
      "38 훈련 MSE: 0.70467514 \t희소 손실: 0.05645452 \t전체 손실: 0.023179524\n",
      "39 훈련 MSE: 0.70476866 \t희소 손실: 0.037683845 \t전체 손실: 0.019191563\n",
      "40 훈련 MSE: 0.7048187 \t희소 손실: 0.03307556 \t전체 손실: 0.017912507\n",
      "41 훈련 MSE: 0.7047399 \t희소 손실: 0.035527527 \t전체 손실: 0.018570889\n",
      "42 훈련 MSE: 0.70485914 \t희소 손실: 0.029943487 \t전체 손실: 0.017299853\n",
      "43 훈련 MSE: 0.70495915 \t희소 손실: 0.054906715 \t전체 손실: 0.022754617\n",
      "44 훈련 MSE: 0.7049049 \t희소 손실: 0.032150615 \t전체 손실: 0.01809168\n",
      "45 훈련 MSE: 0.7049343 \t희소 손실: 0.054782584 \t전체 손실: 0.022084907\n",
      "46 훈련 MSE: 0.7046562 \t희소 손실: 0.036546916 \t전체 손실: 0.01830202\n",
      "47 훈련 MSE: 0.7048627 \t희소 손실: 0.04285598 \t전체 손실: 0.01913426\n",
      "48 훈련 MSE: 0.70483756 \t희소 손실: 0.04221758 \t전체 손실: 0.019337103\n",
      "49 훈련 MSE: 0.70456356 \t희소 손실: 0.050503954 \t전체 손실: 0.02192307\n",
      "50 훈련 MSE: 0.704849 \t희소 손실: 0.032584067 \t전체 손실: 0.01826416\n",
      "51 훈련 MSE: 0.7050262 \t희소 손실: 0.050802454 \t전체 손실: 0.021666948\n",
      "52 훈련 MSE: 0.70474577 \t희소 손실: 0.027270457 \t전체 손실: 0.016154775\n",
      "53 훈련 MSE: 0.70461047 \t희소 손실: 0.049078796 \t전체 손실: 0.021041099\n",
      "54 훈련 MSE: 0.7049404 \t희소 손실: 0.06027465 \t전체 손실: 0.023400078\n",
      "55 훈련 MSE: 0.704887 \t희소 손실: 0.13866566 \t전체 손실: 0.038282342\n",
      "56 훈련 MSE: 0.7049574 \t희소 손실: 0.040830113 \t전체 손실: 0.019480802\n",
      "57 훈련 MSE: 0.7048474 \t희소 손실: 0.06804258 \t전체 손실: 0.024142468\n",
      "58 훈련 MSE: 0.70490736 \t희소 손실: 0.07371303 \t전체 손실: 0.025353152\n",
      "59 훈련 MSE: 0.7048388 \t희소 손실: 0.05028642 \t전체 손실: 0.020932727\n",
      "60 훈련 MSE: 0.70479083 \t희소 손실: 0.03540106 \t전체 손실: 0.017771833\n",
      "61 훈련 MSE: 0.70493966 \t희소 손실: 0.043558907 \t전체 손실: 0.018896509\n",
      "62 훈련 MSE: 0.70486355 \t희소 손실: 0.042882703 \t전체 손실: 0.018792689\n",
      "63 훈련 MSE: 0.70471096 \t희소 손실: 0.04156083 \t전체 손실: 0.01881256\n",
      "64 훈련 MSE: 0.7045731 \t희소 손실: 0.04649141 \t전체 손실: 0.019597847\n",
      "65 훈련 MSE: 0.7047675 \t희소 손실: 0.05490572 \t전체 손실: 0.021400344\n",
      "66 훈련 MSE: 0.704478 \t희소 손실: 0.057606034 \t전체 손실: 0.021899268\n",
      "67 훈련 MSE: 0.70473117 \t희소 손실: 0.06165259 \t전체 손실: 0.022753023\n",
      "68 훈련 MSE: 0.7047347 \t희소 손실: 0.0539909 \t전체 손실: 0.021262221\n",
      "69 훈련 MSE: 0.70458245 \t희소 손실: 0.03995867 \t전체 손실: 0.018706633\n",
      "70 훈련 MSE: 0.70483875 \t희소 손실: 0.05473187 \t전체 손실: 0.021372091\n",
      "71 훈련 MSE: 0.70470655 \t희소 손실: 0.049876384 \t전체 손실: 0.020722505\n",
      "72 훈련 MSE: 0.70475495 \t희소 손실: 0.064231575 \t전체 손실: 0.023715252\n",
      "73 훈련 MSE: 0.7048407 \t희소 손실: 0.06482697 \t전체 손실: 0.023236074\n",
      "74 훈련 MSE: 0.7046737 \t희소 손실: 0.07983266 \t전체 손실: 0.025930448\n",
      "75 훈련 MSE: 0.70480746 \t희소 손실: 0.04487704 \t전체 손실: 0.019332971\n",
      "76 훈련 MSE: 0.70502543 \t희소 손실: 0.10607215 \t전체 손실: 0.030738227\n",
      "77 훈련 MSE: 0.70471036 \t희소 손실: 0.07365614 \t전체 손실: 0.024953093\n",
      "78 훈련 MSE: 0.7045609 \t희소 손실: 0.054648962 \t전체 손실: 0.020791333\n",
      "79 훈련 MSE: 0.7048357 \t희소 손실: 0.06136309 \t전체 손실: 0.022674348\n",
      "80 훈련 MSE: 0.7048542 \t희소 손실: 0.06847518 \t전체 손실: 0.02390036\n",
      "81 훈련 MSE: 0.7047953 \t희소 손실: 0.07997737 \t전체 손실: 0.025382046\n",
      "82 훈련 MSE: 0.70481974 \t희소 손실: 0.070328325 \t전체 손실: 0.024620019\n",
      "83 훈련 MSE: 0.7047722 \t희소 손실: 0.044937093 \t전체 손실: 0.019087782\n",
      "84 훈련 MSE: 0.7048807 \t희소 손실: 0.05482406 \t전체 손실: 0.020829547\n",
      "85 훈련 MSE: 0.70477843 \t희소 손실: 0.072529726 \t전체 손실: 0.024967756\n",
      "86 훈련 MSE: 0.7049862 \t희소 손실: 0.074650966 \t전체 손실: 0.025132779\n",
      "87 훈련 MSE: 0.7048109 \t희소 손실: 0.048156057 \t전체 손실: 0.020079378\n",
      "88 훈련 MSE: 0.7045681 \t희소 손실: 0.042674508 \t전체 손실: 0.019218262\n",
      "89 훈련 MSE: 0.7049342 \t희소 손실: 0.091343276 \t전체 손실: 0.02935951\n",
      "90 훈련 MSE: 0.70475096 \t희소 손실: 0.10890689 \t전체 손실: 0.0320644\n",
      "91 훈련 MSE: 0.7048048 \t희소 손실: 0.14743108 \t전체 손실: 0.039894674\n",
      "92 훈련 MSE: 0.7048771 \t희소 손실: 0.13553852 \t전체 손실: 0.038833402\n",
      "93 훈련 MSE: 0.70489264 \t희소 손실: 0.056466527 \t전체 손실: 0.021886986\n",
      "94 훈련 MSE: 0.7045744 \t희소 손실: 0.040551834 \t전체 손실: 0.018315908\n",
      "95 훈련 MSE: 0.7047106 \t희소 손실: 0.041130543 \t전체 손실: 0.01899023\n",
      "96 훈련 MSE: 0.70486784 \t희소 손실: 0.036343668 \t전체 손실: 0.017288603\n",
      "97 훈련 MSE: 0.70480984 \t희소 손실: 0.10057676 \t전체 손실: 0.030357333\n",
      "98 훈련 MSE: 0.70474297 \t희소 손실: 0.059611574 \t전체 손실: 0.022280049\n",
      "99 훈련 MSE: 0.7050048 \t희소 손실: 0.06945995 \t전체 손실: 0.024482772\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = len(X_train) // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = next(shuffle_batch(X_train, y_train, batch_size))\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        reconstruction_loss_val, sparsity_loss_val, loss_val = sess.run([reconstruction_loss, sparsity_loss, loss], feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"훈련 MSE:\", reconstruction_loss_val, \"\\t희소 손실:\", sparsity_loss_val, \"\\t전체 손실:\", loss_val)\n",
    "        saver.save(sess, \"./my_model_sparse.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
